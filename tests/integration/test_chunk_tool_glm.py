# Copyright (c) 2025 ByteDance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

import asyncio
import os
import sys
import tempfile
import unittest
from pathlib import Path
from unittest import SkipTest

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from trae_agent.tools.base import ToolCallArguments
from trae_agent.tools.chunk_tool import TextChunkTool
from trae_agent.utils.config import ModelConfig, ModelProvider
from trae_agent.utils.llm_clients.glm_client import GLMClient


class TestTextChunkToolWithGLM(unittest.IsolatedAsyncioTestCase):
    """Integration tests for TextChunkTool using real GLM API."""

    def setUp(self):
        # Skip if running in CI or if we want to avoid API costs
        if os.getenv("SKIP_GLM_TESTS") == "1":
            raise SkipTest("GLM tests skipped (SKIP_GLM_TESTS=1)")
            
        # GLM API configuration
        self.api_key = "e34be58db90244488b2f5ad00008698b.wlAPdq5wKIVuJiNA"
        self.base_url = "https://open.bigmodel.cn/api/paas/v4/"
        
        # Create GLM model config
        model_provider = ModelProvider(
            api_key=self.api_key,
            provider="glm",
            base_url=self.base_url
        )
        
        model_config = ModelConfig(
            model="glm-4.5",
            model_provider=model_provider,
            max_tokens=1000,
            temperature=0.3,
            top_p=1.0,
            top_k=0,
            parallel_tool_calls=False,
            max_retries=3,
        )
        
        # Create real GLM client
        llm_client = GLMClient(model_config)
        
        # Create tool with real GLM client
        self.tool = TextChunkTool(model_provider="glm", llm_client=llm_client)
        
        # Create test file with Chinese content
        self.test_file = tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8')
        self.test_content = """äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥åˆ†ä¸ºå‡ ä¸ªé‡è¦é˜¶æ®µï¼š

1950å¹´ä»£ï¼šè‰¾ä¼¦Â·å›¾çµæå‡ºå›¾çµæµ‹è¯•ï¼Œæ ‡å¿—ç€äººå·¥æ™ºèƒ½ç†è®ºåŸºç¡€çš„å»ºç«‹ã€‚è¿™ä¸ªæµ‹è¯•æå‡ºäº†ä¸€ä¸ªé‡è¦é—®é¢˜ï¼šæœºå™¨èƒ½æ€è€ƒå—ï¼Ÿ

1956å¹´ï¼šè¾¾ç‰¹èŒ…æ–¯ä¼šè®®æ­£å¼æå‡º"äººå·¥æ™ºèƒ½"è¿™ä¸€æ¦‚å¿µã€‚çº¦ç¿°Â·éº¦å¡é”¡ã€é©¬æ–‡Â·æ˜æ–¯åŸºç­‰è®¡ç®—æœºç§‘å­¦å®¶èšé›†åœ¨ä¸€èµ·ï¼Œè®¨è®ºæœºå™¨æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚

1960-70å¹´ä»£ï¼šä¸“å®¶ç³»ç»Ÿå…´èµ·ï¼Œå¦‚MYCINåŒ»ç–—è¯Šæ–­ç³»ç»Ÿã€‚è¿™äº›ç³»ç»Ÿèƒ½å¤Ÿåœ¨ç‰¹å®šé¢†åŸŸå†…æ¨¡æ‹Ÿäººç±»ä¸“å®¶çš„å†³ç­–è¿‡ç¨‹ã€‚

1980å¹´ä»£ï¼šæœºå™¨å­¦ä¹ ç†è®ºé€æ¸å‘å±•ï¼Œç¥ç»ç½‘ç»œé‡è·å…³æ³¨ã€‚åå‘ä¼ æ’­ç®—æ³•çš„æå‡ºä¸ºæ·±åº¦å­¦ä¹ å¥ å®šäº†åŸºç¡€ã€‚

1990å¹´ä»£ï¼šäº’è”ç½‘æ™®åŠæ¨åŠ¨äº†æ•°æ®ç§¯ç´¯å’Œç®—æ³•æ”¹è¿›ã€‚å¤§é‡æ•°æ®çš„å¯è·å¾—æ€§ä¸ºæœºå™¨å­¦ä¹ ç®—æ³•æä¾›äº†æ›´å¥½çš„è®­ç»ƒç´ æã€‚

2000å¹´ä»£ï¼šæ·±åº¦å­¦ä¹ çªç ´ï¼Œå›¾åƒè¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†å–å¾—é‡å¤§è¿›å±•ã€‚æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œåœ¨å›¾åƒè¯†åˆ«ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

2010å¹´ä»£ï¼šå¤§è¯­è¨€æ¨¡å‹å‡ºç°ï¼Œå¦‚GPTã€BERTç­‰ã€‚è¿™äº›æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆä»»åŠ¡ä¸­å±•ç°å‡ºæƒŠäººçš„èƒ½åŠ›ã€‚

2020å¹´ä»£ï¼šChatGPTç­‰å¯¹è¯å¼AIå¹¿æ³›åº”ç”¨ï¼ŒAGIæˆä¸ºæ–°ç›®æ ‡ã€‚äººå·¥æ™ºèƒ½å¼€å§‹åœ¨æ›´å¤šé¢†åŸŸå±•ç°å‡ºæ¥è¿‘äººç±»çš„èƒ½åŠ›ã€‚

äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨å„è¡Œä¸šçš„åº”ç”¨åŒ…æ‹¬ï¼š
- åŒ»ç–—ï¼šè¾…åŠ©è¯Šæ–­ã€è¯ç‰©å‘ç°ã€ä¸ªæ€§åŒ–æ²»ç–—
- é‡‘èï¼šé£é™©è¯„ä¼°ã€ç®—æ³•äº¤æ˜“ã€å®¢æˆ·æœåŠ¡  
- æ•™è‚²ï¼šä¸ªæ€§åŒ–å­¦ä¹ ã€æ™ºèƒ½è¾…å¯¼
- äº¤é€šï¼šè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å¯¼èˆª
- åˆ¶é€ ä¸šï¼šè´¨é‡æ§åˆ¶ã€é¢„æµ‹æ€§ç»´æŠ¤
- å¨±ä¹ï¼šå†…å®¹æ¨èã€æ¸¸æˆAI

æœªæ¥å‘å±•è¶‹åŠ¿åŒ…æ‹¬æ›´å¼ºçš„æ¨ç†èƒ½åŠ›ã€å¤šæ¨¡æ€èåˆã€è¾¹ç¼˜è®¡ç®—éƒ¨ç½²ç­‰ã€‚"""
        
        self.test_file.write(self.test_content)
        self.test_file.close()

    def tearDown(self):
        # Clean up test file
        if os.path.exists(self.test_file.name):
            os.unlink(self.test_file.name)

    async def test_chunk_analysis_with_glm(self):
        """Test chunk analysis using real GLM API."""
        print(f"\nğŸ”¬ Testing TextChunkTool with GLM-4.5")
        print(f"ğŸ“„ Test file: {self.test_file.name}")
        print(f"ğŸ“ Content length: {len(self.test_content)} characters")
        
        # Get first ~500 characters for analysis (simulating document chunk processing)
        start_pos = 0
        end_pos = 500
        query = "ä»è¿™ä¸ªæ–‡æ¡£ç‰‡æ®µä¸­æå–å…³é”®æ—¶é—´èŠ‚ç‚¹å’Œå†å²äº‹ä»¶ï¼Œç”¨äºæ„å»ºAIå‘å±•æ—¶é—´çº¿"
        enhanced_prompt = "ä½œä¸ºæ–‡æ¡£åˆ†æå­ä»£ç†ï¼Œåˆ†æè¿™ä¸ªAIå†å²æ–‡æ¡£ç‰‡æ®µã€‚åªå¤„ç†ç‰‡æ®µå†…å®¹ï¼Œæå–ï¼š1)æ˜ç¡®æ—¶é—´ç‚¹(å¹´ä»£) 2)å…³é”®äººç‰© 3)é‡è¦äº‹ä»¶ã€‚è¾“å‡ºç®€æ´ï¼Œä¾¿äºåç»­åˆå¹¶å¤„ç†ã€‚å¦‚æœä¿¡æ¯ä¸å®Œæ•´ï¼Œæ ‡è®°ä¸ºéƒ¨åˆ†ä¿¡æ¯ã€‚"
        
        arguments = ToolCallArguments({
            "file_path": self.test_file.name,
            "start_pos": start_pos,
            "end_pos": end_pos,
            "query": query,
            "enhanced_prompt": enhanced_prompt,
            "chunk_id": "ai_history_chunk_001"
        })
        
        print(f"ğŸ¯ Query: {query}")
        print(f"ğŸ“ Chunk position: {start_pos}-{end_pos}")
        print("â³ Sub-agent analyzing document chunk with GLM...")
        
        result = await self.tool.execute(arguments)
        
        # Verify the result
        self.assertIsNone(result.error, f"Tool execution failed: {result.error}")
        self.assertIsNotNone(result.output)
        self.assertGreater(len(result.output), 50)
        
        print(f"âœ… Sub-agent Chunk Analysis Result:")
        print(f"ğŸ“Š Response length: {len(result.output)} characters")
        print(f"ğŸ¤– GLM Chunk Analysis: {result.output}")
        
        # Check for chunk processing effectiveness and key extraction
        chunk_terms = ["æ—¶é—´", "äº‹ä»¶", "ç‰‡æ®µ", "ç®€æ´", "åˆå¹¶"] + ["1950å¹´ä»£", "å›¾çµ", "1956å¹´", "è¾¾ç‰¹èŒ…æ–¯", "äººå·¥æ™ºèƒ½"]
        found_terms = [term for term in chunk_terms if term in result.output]
        
        self.assertGreater(len(found_terms), 2, 
                          f"Expected chunk processing to extract key information, found: {found_terms}")
        
        print(f"âœ… Found chunk processing and key terms: {found_terms}")

    async def test_simple_chunk_processing(self):
        """Test simple chunk processing with GLM for sub-agent workflow."""
        print(f"\nğŸ”¬ Testing Sub-agent Chunk Processing with GLM-4.5")
        
        # Test a smaller chunk - first 200 characters (realistic chunk size)
        start_pos = 0
        end_pos = 200
        query = "ä½œä¸ºå­ä»£ç†ï¼Œå¿«é€Ÿå¤„ç†è¿™ä¸ªæ–‡æ¡£ç‰‡æ®µ"
        enhanced_prompt = "ä½œä¸ºæ–‡æ¡£å¤„ç†å­ä»£ç†ï¼Œå¿«é€Ÿåˆ†æè¿™ä¸ªæ–‡æ¡£ç‰‡æ®µã€‚åªæå–æ ¸å¿ƒä¿¡æ¯ï¼Œè¾“å‡ºç®€æ´ï¼Œä¾¿äºä¸å…¶ä»–ç‰‡æ®µç»“æœåˆå¹¶ã€‚å¦‚æœå†…å®¹ä¸å®Œæ•´ï¼Œæ ‡æ˜è¾¹ç•Œä¿¡æ¯ã€‚"
        
        arguments = ToolCallArguments({
            "file_path": self.test_file.name,
            "start_pos": start_pos,
            "end_pos": end_pos,
            "query": query,
            "enhanced_prompt": enhanced_prompt
        })
        
        print(f"ğŸ“ Sub-agent processing chunk: {start_pos}-{end_pos}")
        result = await self.tool.execute(arguments)
        
        # Verify result for sub-agent chunk processing
        self.assertIsNone(result.error)
        self.assertIsNotNone(result.output)
        
        # Check for sub-agent processing indicators
        subagent_terms = ["æ ¸å¿ƒ", "ç®€æ´", "ç‰‡æ®µ", "åˆå¹¶", "è¾¹ç•Œ"]
        found_subagent_terms = [term for term in subagent_terms if term in result.output]
        
        print(f"âœ… Sub-agent chunk processing result: {result.output[:100]}...")
        print(f"ğŸ¤– Found sub-agent processing terms: {found_subagent_terms}")


if __name__ == "__main__":
    # Note: These tests make real API calls to GLM
    # Set SKIP_GLM_TESTS=1 to skip them
    unittest.main()